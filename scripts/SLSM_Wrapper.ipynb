{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iwg373Kf0uGO",
        "outputId": "48df1024-b462-4eaa-9589-45fce2794f35"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf /content/multi-challenge\n",
        "!git clone https://github.com/iemppu/multi-challenge /content/multi-challenge\n",
        "!ls -la /content/multi-challenge\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rcFx4iOU05nm",
        "outputId": "e9318c4a-2e38-4445-d4ca-144553ca8b7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into '/content/multi-challenge'...\n",
            "remote: Enumerating objects: 148, done.\u001b[K\n",
            "remote: Counting objects: 100% (148/148), done.\u001b[K\n",
            "remote: Compressing objects: 100% (134/134), done.\u001b[K\n",
            "remote: Total 148 (delta 69), reused 58 (delta 13), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (148/148), 3.26 MiB | 7.21 MiB/s, done.\n",
            "Resolving deltas: 100% (69/69), done.\n",
            "total 40\n",
            "drwxr-xr-x 5 root root 4096 Jan  4 00:39 .\n",
            "drwxr-xr-x 1 root root 4096 Jan  4 00:39 ..\n",
            "drwxr-xr-x 3 root root 4096 Jan  4 00:39 data\n",
            "drwxr-xr-x 8 root root 4096 Jan  4 00:39 .git\n",
            "-rw-r--r-- 1 root root 3853 Jan  4 00:39 main.py\n",
            "-rw-r--r-- 1 root root 3968 Jan  4 00:39 README.md\n",
            "-rw-r--r-- 1 root root  129 Jan  4 00:39 requirements.txt\n",
            "-rw-r--r-- 1 root root 3923 Jan  4 00:39 run_judge_eval.py\n",
            "-rw-r--r-- 1 root root 2211 Jan  4 00:39 run_slsm_multichallenge_gpt4o.py\n",
            "drwxr-xr-x 3 root root 4096 Jan  4 00:39 src\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/multi-challenge\n",
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pv_lKfzH093e",
        "outputId": "f2ae0c9f-52f7-4034-979e-2edbe7ad54df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/multi-challenge\n",
            "Requirement already satisfied: pydantic<3,==2.11 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 1)) (2.11.0)\n",
            "Requirement already satisfied: python-dotenv==1.0.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 2)) (1.0.1)\n",
            "Requirement already satisfied: torch==2.5.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 3)) (2.5.1)\n",
            "Requirement already satisfied: tqdm>=4.67 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 4)) (4.67.1)\n",
            "Requirement already satisfied: transformers==4.44.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 5)) (4.44.1)\n",
            "Requirement already satisfied: openai==1.55.3 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 6)) (1.55.3)\n",
            "Requirement already satisfied: httpx==0.27.2 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 7)) (0.27.2)\n",
            "Requirement already satisfied: httpcore==1.0.7 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 8)) (1.0.7)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,==2.11->-r requirements.txt (line 1)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,==2.11->-r requirements.txt (line 1)) (2.33.0)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,==2.11->-r requirements.txt (line 1)) (4.15.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,==2.11->-r requirements.txt (line 1)) (0.4.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch==2.5.1->-r requirements.txt (line 3)) (3.20.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch==2.5.1->-r requirements.txt (line 3)) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch==2.5.1->-r requirements.txt (line 3)) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch==2.5.1->-r requirements.txt (line 3)) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.12/dist-packages (from torch==2.5.1->-r requirements.txt (line 3)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.12/dist-packages (from torch==2.5.1->-r requirements.txt (line 3)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.12/dist-packages (from torch==2.5.1->-r requirements.txt (line 3)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.12/dist-packages (from torch==2.5.1->-r requirements.txt (line 3)) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.12/dist-packages (from torch==2.5.1->-r requirements.txt (line 3)) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.12/dist-packages (from torch==2.5.1->-r requirements.txt (line 3)) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.12/dist-packages (from torch==2.5.1->-r requirements.txt (line 3)) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.12/dist-packages (from torch==2.5.1->-r requirements.txt (line 3)) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.12/dist-packages (from torch==2.5.1->-r requirements.txt (line 3)) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.12/dist-packages (from torch==2.5.1->-r requirements.txt (line 3)) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.12/dist-packages (from torch==2.5.1->-r requirements.txt (line 3)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.12/dist-packages (from torch==2.5.1->-r requirements.txt (line 3)) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.12/dist-packages (from torch==2.5.1->-r requirements.txt (line 3)) (3.1.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch==2.5.1->-r requirements.txt (line 3)) (75.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.12/dist-packages (from torch==2.5.1->-r requirements.txt (line 3)) (1.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.12/dist-packages (from transformers==4.44.1->-r requirements.txt (line 5)) (0.36.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers==4.44.1->-r requirements.txt (line 5)) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers==4.44.1->-r requirements.txt (line 5)) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers==4.44.1->-r requirements.txt (line 5)) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers==4.44.1->-r requirements.txt (line 5)) (2025.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers==4.44.1->-r requirements.txt (line 5)) (2.32.4)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.12/dist-packages (from transformers==4.44.1->-r requirements.txt (line 5)) (0.7.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.12/dist-packages (from transformers==4.44.1->-r requirements.txt (line 5)) (0.19.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai==1.55.3->-r requirements.txt (line 6)) (4.12.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai==1.55.3->-r requirements.txt (line 6)) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai==1.55.3->-r requirements.txt (line 6)) (0.12.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai==1.55.3->-r requirements.txt (line 6)) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx==0.27.2->-r requirements.txt (line 7)) (2025.11.12)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx==0.27.2->-r requirements.txt (line 7)) (3.11)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.0.7->-r requirements.txt (line 8)) (0.14.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy==1.13.1->torch==2.5.1->-r requirements.txt (line 3)) (1.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.44.1->-r requirements.txt (line 5)) (1.2.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch==2.5.1->-r requirements.txt (line 3)) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.44.1->-r requirements.txt (line 5)) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.44.1->-r requirements.txt (line 5)) (2.5.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n",
        "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n"
      ],
      "metadata": {
        "id": "Ddd7L0XI1BdL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Implementation of SLSM"
      ],
      "metadata": {
        "id": "L9m3dksV1KRx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from src.data_loader import DataLoader\n",
        "\n",
        "# 路径与你 repo 对齐\n",
        "BENCHMARK = \"data/benchmark_questions.jsonl\"\n",
        "\n",
        "dl = DataLoader(input_file=BENCHMARK)\n",
        "dl.load_data()\n",
        "\n",
        "conversations = dl.get_conversations()\n",
        "\n",
        "print(f\"Loaded {len(conversations)} conversations\")\n",
        "print(type(conversations[0]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P8XUR8-31LP4",
        "outputId": "383772f0-34f1-4679-a3cb-1a60bbbfd561"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 273 conversations\n",
            "<class 'src.conversation.Conversation'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conv = conversations[0]\n",
        "messages = conv.conversation   # list[{\"role\",\"content\"}]\n",
        "\n",
        "print(messages[0].keys())      # 应该是 dict with 'role', 'content'\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_biwrXka1NtN",
        "outputId": "af5c658f-2f59-4ec2-9e78-9e7e2f712261"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['role', 'content'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# Print full conversation + SLSM sanity-check\n",
        "# =========================\n",
        "\n",
        "# ---- imports ----\n",
        "from src.data_loader import DataLoader\n",
        "from src.models.openai import OpenAIModel\n",
        "from src.slsm_wrapper import (\n",
        "    SLSMConfig,\n",
        "    SLSMController,\n",
        "    SLSMWrapper,\n",
        ")\n",
        "\n",
        "# ---- load conversations ----\n",
        "BENCHMARK = \"data/benchmark_questions.jsonl\"\n",
        "dl = DataLoader(input_file=BENCHMARK)\n",
        "dl.load_data()\n",
        "conversations = dl.get_conversations()\n",
        "\n",
        "# ---- pick one conversation ----\n",
        "conv = conversations[0]\n",
        "messages = conv.conversation\n",
        "\n",
        "# ---- print full conversation (indexed) ----\n",
        "print(\"=== FULL CONVERSATION (indexed) ===\")\n",
        "for i, m in enumerate(messages):\n",
        "    role = m.get(\"role\")\n",
        "    content = (m.get(\"content\") or \"\")\n",
        "    # truncate long turns for readability\n",
        "    preview = content if len(content) <= 500 else content[:500] + \" ...[truncated]\"\n",
        "    print(f\"\\n--- turn {i} | {role} ---\\n{preview}\")\n",
        "\n",
        "# ---- controller (cheap, fixed) ----\n",
        "controller_llm = OpenAIModel(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    temp=0\n",
        ")\n",
        "\n",
        "cfg = SLSMConfig(\n",
        "    inject=\"always\",   # 临时强制注入\n",
        "    note_max_items=6,\n",
        ")\n",
        "\n",
        "controller = SLSMController(controller_llm, cfg)\n",
        "wrapper = SLSMWrapper(controller, cfg)\n",
        "\n",
        "# ---- underlying model (tested model) ----\n",
        "underlying_llm = OpenAIModel(\n",
        "    model=\"gpt-4o-2024-08-06\",\n",
        "    temp=0\n",
        ")\n",
        "\n",
        "# ---- baseline ----\n",
        "baseline_resp = underlying_llm.generate(messages)\n",
        "\n",
        "# ---- SLSM wrapped ----\n",
        "slsm_resp = wrapper.generate_last_turn(\n",
        "    underlying_llm=underlying_llm,\n",
        "    original_conversation=messages,\n",
        ")\n",
        "\n",
        "print(\"\\n=== BASELINE ===\")\n",
        "print(baseline_resp[:500])\n",
        "print(\"\\n=== SLSM ===\")\n",
        "print(slsm_resp[:500])\n",
        "\n",
        "# ---- inspect state + injected note ----\n",
        "state = wrapper.track_state(messages)\n",
        "print(\"\\n=== RAW STATE FACTS (controller output, pre-gating) ===\")\n",
        "print(state.facts)\n",
        "\n",
        "msgs = wrapper.build_final_messages(messages, state)\n",
        "print(\"\\n=== FINAL MSG ROLES (first 6) ===\")\n",
        "print([m[\"role\"] for m in msgs[:6]])\n",
        "\n",
        "print(\"\\n=== INJECTED NOTE (first 1200 chars) ===\")\n",
        "print(msgs[0][\"role\"], msgs[0][\"content\"][:1200])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Uu7jLJy1QGr",
        "outputId": "957c2b23-82c9-4d2b-b4b0-b72c82b16c3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== FULL CONVERSATION (indexed) ===\n",
            "\n",
            "--- turn 0 | user ---\n",
            "Hello!  I am an International relations expert working at the UN headquarters. My work requires me to consistently meet with diplomats from various countries. I hate using taxis or public transportation in New York. I prefer venues that are within a 5-minute walk from the UN headquarters.\n",
            "\n",
            "--- turn 1 | assistant ---\n",
            "Hello! It's great to hear that you're looking for places near the UN headquarters in New York. Here are a few suggestions that are within a 5-minute walk:\n",
            "\n",
            "1. Dag Hammarskjold Plaza: This public park is just across the street from the UN headquarters. It's a great place for a peaceful walk or a quick meeting.\n",
            "\n",
            "2. The Delegates Dining Room: Located within the UN headquarters itself, this is a convenient place for a meeting over lunch or dinner.\n",
            "\n",
            "3. The Roosevelt Hotel: This historic hotel is just ...[truncated]\n",
            "\n",
            "--- turn 2 | user ---\n",
            " I am meeting a German diplomat on Friday. I am looking for a suitable place to have lunch with him, preferably an up-class restaurant. I do not need to other arrangements, particularly security arrangements. Can you indicate for me some places where I can hold that meeting?\n",
            "\n",
            "=== BASELINE ===\n",
            "Certainly! Here are a few upscale restaurants near the UN headquarters that would be suitable for a lunch meeting with a German diplomat:\n",
            "\n",
            "1. **The Modern**: Located at the Museum of Modern Art, The Modern is a Michelin-starred restaurant offering contemporary American cuisine with a beautiful view of the museum's sculpture garden. It's a bit further than a 5-minute walk, but it's a top choice for an upscale dining experience.\n",
            "\n",
            "2. **Aquavit**: This two-Michelin-starred restaurant offers Scandina\n",
            "\n",
            "=== SLSM ===\n",
            "Certainly! Here are some up-class restaurants within a 5-minute walk from the UN headquarters that would be suitable for a lunch meeting with a German diplomat:\n",
            "\n",
            "1. **The Delegates Dining Room**: Located within the UN headquarters, this dining room offers a sophisticated setting with international cuisine and stunning views of the East River.\n",
            "\n",
            "2. **The Palm Too**: Just a short walk away, this classic American steakhouse is known for its high-quality steaks and seafood, providing a refined atmosp\n",
            "\n",
            "=== RAW STATE FACTS (controller output, pre-gating) ===\n",
            "[{'id': 'F1', 'text': 'User is an International relations expert working at the UN headquarters.', 'support_turns': [0], 'evidence': 'I am an International relations expert working at the UN headquarters.'}]\n",
            "\n",
            "=== FINAL MSG ROLES (first 6) ===\n",
            "['system', 'user', 'assistant', 'user']\n",
            "\n",
            "=== INJECTED NOTE (first 1200 chars) ===\n",
            "system [SLSM MEMORY NOTE]\n",
            "Constraints:\n",
            "- [satisfied] User prefers venues that are within a 5-minute walk from the UN headquarters.\n",
            "- [satisfied] User hates using taxis or public transportation in New York.\n",
            "- [satisfied] User is looking for an up-class restaurant for a lunch meeting with a German diplomat.\n",
            "- [satisfied] User does not need other arrangements, particularly security arrangements.\n",
            "User facts/preferences:\n",
            "- User is an International relations expert working at the UN headquarters.\n",
            "\n",
            "Follow the constraints above.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This cell will pull new code from remote to this runtine\n",
        "%cd /content/multi-challenge\n",
        "!git status\n",
        "!git pull"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rwjvvCbbDZB7",
        "outputId": "e0ba9482-fce3-4334-9e05-647b68b6890e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/multi-challenge\n",
            "On branch main\n",
            "Your branch is up to date with 'origin/main'.\n",
            "\n",
            "Changes not staged for commit:\n",
            "  (use \"git add <file>...\" to update what will be committed)\n",
            "  (use \"git restore <file>...\" to discard changes in working directory)\n",
            "\t\u001b[31mmodified:   run_slsm_multichallenge_gpt4o.py\u001b[m\n",
            "\n",
            "Untracked files:\n",
            "  (use \"git add <file>...\" to include in what will be committed)\n",
            "\t\u001b[31msrc/__pycache__/\u001b[m\n",
            "\t\u001b[31msrc/models/__pycache__/\u001b[m\n",
            "\n",
            "no changes added to commit (use \"git add\" and/or \"git commit -a\")\n",
            "Already up to date.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Run and test with gpt-4o-mini-controlled response by gpt-4o"
      ],
      "metadata": {
        "id": "SNebkmepbI0x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python run_slsm_multichallenge_gpt4o.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r-h4yknHbH0m",
        "outputId": "9e49e2da-cf97-470b-cf54-4dca8c07a911"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 273 conversations\n",
            "Running SLSM-controlled GPT-4o: 100% 50/50 [1:02:56<00:00, 75.52s/it]\n",
            "\n",
            "Done. Results saved to:\n",
            "  data/final_model_responses/gpt-4o-2024-08-06_slsm-gpt-4o-mini.jsonl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "src = \"data/final_model_responses/gpt-4o-2024-08-06_responses.jsonl\"\n",
        "dst = \"data/final_model_responses/gpt-4o-2024-08-06_responses_first50.jsonl\"\n",
        "\n",
        "with open(src, \"r\", encoding=\"utf-8\") as f:\n",
        "    lines = [next(f) for _ in range(50)]\n",
        "\n",
        "with open(dst, \"w\", encoding=\"utf-8\") as g:\n",
        "    for line in lines:\n",
        "        g.write(line)\n",
        "\n",
        "print(\"Wrote:\", dst, \"lines=\", len(lines))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9FC78ANTsWz8",
        "outputId": "c3539cfc-4eed-478c-cfc2-0fb6b75eec2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote: data/final_model_responses/gpt-4o-2024-08-06_responses_first50.jsonl lines= 50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = \"data/final_model_responses/gpt-4o-2024-08-06_responses_first50.jsonl\"\n",
        "b = \"data/final_model_responses/gpt-4o-2024-08-06_slsm-gpt-4o-mini.jsonl\"\n",
        "\n",
        "def ids(path):\n",
        "    out=[]\n",
        "    with open(path,\"r\",encoding=\"utf-8\") as f:\n",
        "        for line in f:\n",
        "            out.append(json.loads(line)[\"question_id\"])\n",
        "    return out\n",
        "\n",
        "A=ids(a); B=ids(b)\n",
        "print(\"baseline lines:\", len(A), \"unique:\", len(set(A)))\n",
        "print(\"slsm lines:\", len(B), \"unique:\", len(set(B)))\n",
        "print(\"same order:\", A==B)\n",
        "print(\"same set:\", set(A)==set(B))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        },
        "id": "iPe2sscCscx8",
        "outputId": "7765d808-e307-46b7-a2ba-033cca372683"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'question_id'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3563234583.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mA\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mB\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"baseline lines:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"unique:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"slsm lines:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"unique:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3563234583.py\u001b[0m in \u001b[0;36mids\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m             \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"question_id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'question_id'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# Run judge-based evaluation on first 50 samples\n",
        "# Baseline vs SLSM-controlled GPT-4o\n",
        "# =========================\n",
        "\n",
        "%cd /content/multi-challenge\n",
        "!mkdir -p outputs_first50\n",
        "\n",
        "# ---- Baseline: GPT-4o (first 50) ----\n",
        "!python -m run_judge_eval \\\n",
        "  --responses data/final_model_responses/gpt-4o-2024-08-06_responses_first50.jsonl \\\n",
        "  --out_json outputs_first50/gpt4o_baseline_judge_results.json \\\n",
        "  --out_csv outputs_first50/gpt4o_baseline_judge_results.csv \\\n",
        "  --workers 1 \\\n",
        "  --attempts 1\n",
        "\n",
        "\n",
        "print(\"Done 1. Judge evaluation results saved to outputs_first50/\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6LTQNhitswLN",
        "outputId": "e9333489-9540-47b8-a622-175e2a7bad6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/multi-challenge\n",
            "Evaluating responses: 100% 50/50 [01:22<00:00,  1.66s/it]\n",
            "\n",
            "=== SCORES ===\n",
            "{\n",
            "  \"overall_score\": 0.5835577786328074,\n",
            "  \"axis_scores\": {\n",
            "    \"INFERENCE_MEMORY\": 0.8849557522123894,\n",
            "    \"RELIABLE_VERSION_EDITING\": 0.0,\n",
            "    \"SELF_COHERENCE\": 0.0,\n",
            "    \"INSTRUCTION_RETENTION\": 1.4492753623188406\n",
            "  }\n",
            "}\n",
            "\n",
            "Saved: outputs_first50/gpt4o_baseline_judge_results.json\n",
            "Saved: outputs_first50/gpt4o_baseline_judge_results.csv\n",
            "Traceback (most recent call last):\n",
            "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
            "  File \"<frozen runpy>\", line 88, in _run_code\n",
            "  File \"/content/multi-challenge/run_judge_eval.py\", line 101, in <module>\n",
            "    main()\n",
            "  File \"/content/multi-challenge/run_judge_eval.py\", line 81, in main\n",
            "    responses = load_responses_jsonl(args.responses)\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/multi-challenge/run_judge_eval.py\", line 55, in load_responses_jsonl\n",
            "    qid = obj[\"QUESTION_ID\"]\n",
            "          ~~~^^^^^^^^^^^^^^^\n",
            "KeyError: 'QUESTION_ID'\n",
            "Done. Judge evaluation results saved to outputs_first50/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# Fix SLSM response JSONL format for run_judge_eval (QUESTION_ID key)\n",
        "# then run judge eval\n",
        "# =========================\n",
        "\n",
        "%cd /content/multi-challenge\n",
        "!mkdir -p outputs_first50\n",
        "\n",
        "import json\n",
        "\n",
        "src = \"data/final_model_responses/gpt-4o-2024-08-06_slsm-gpt-4o-mini.jsonl\"\n",
        "dst = \"data/final_model_responses/gpt-4o-2024-08-06_slsm-gpt-4o-mini_mcformat.jsonl\"\n",
        "\n",
        "n = 0\n",
        "with open(src, \"r\", encoding=\"utf-8\") as f, open(dst, \"w\", encoding=\"utf-8\") as g:\n",
        "    for line in f:\n",
        "        obj = json.loads(line)\n",
        "\n",
        "        # ---- normalize keys ----\n",
        "        # qid\n",
        "        qid = obj.get(\"QUESTION_ID\", obj.get(\"question_id\", obj.get(\"qid\")))\n",
        "        if qid is None:\n",
        "            raise KeyError(f\"Missing question id in line: {obj.keys()}\")\n",
        "\n",
        "        # response\n",
        "        resp = obj.get(\"RESPONSE\", obj.get(\"response\", obj.get(\"answer\")))\n",
        "        if resp is None:\n",
        "            raise KeyError(f\"Missing response text in line: {obj.keys()}\")\n",
        "\n",
        "        # model name (optional)\n",
        "        model = obj.get(\"MODEL\", obj.get(\"model\", \"UNKNOWN_MODEL\"))\n",
        "\n",
        "        out = {\n",
        "            \"QUESTION_ID\": qid,\n",
        "            \"MODEL\": model,\n",
        "            \"RESPONSE\": resp,\n",
        "        }\n",
        "        g.write(json.dumps(out, ensure_ascii=False) + \"\\n\")\n",
        "        n += 1\n",
        "\n",
        "print(f\"Wrote {n} lines -> {dst}\")\n",
        "\n",
        "# ---- now run judge eval on SLSM file (fixed format) ----\n",
        "!python -m run_judge_eval \\\n",
        "  --responses data/final_model_responses/gpt-4o-2024-08-06_slsm-gpt-4o-mini_mcformat.jsonl \\\n",
        "  --out_json outputs_first50/gpt4o_slsm_judge_results.json \\\n",
        "  --out_csv outputs_first50/gpt4o_slsm_judge_results.csv \\\n",
        "  --workers 1 \\\n",
        "  --attempts 1\n",
        "\n",
        "print(\"Done. SLSM judge results saved to outputs_first50/\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vjtq2xCItlUB",
        "outputId": "a8de1680-58b0-477c-de5b-321a904fc081"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/multi-challenge\n",
            "Wrote 50 lines -> data/final_model_responses/gpt-4o-2024-08-06_slsm-gpt-4o-mini_mcformat.jsonl\n",
            "Evaluating responses: 100% 50/50 [01:33<00:00,  1.86s/it]\n",
            "\n",
            "=== SCORES ===\n",
            "{\n",
            "  \"overall_score\": 3.7574708221110686,\n",
            "  \"axis_scores\": {\n",
            "    \"INFERENCE_MEMORY\": 0.8849557522123894,\n",
            "    \"RELIABLE_VERSION_EDITING\": 0.0,\n",
            "    \"SELF_COHERENCE\": 4.0,\n",
            "    \"INSTRUCTION_RETENTION\": 10.144927536231885\n",
            "  }\n",
            "}\n",
            "\n",
            "Saved: outputs_first50/gpt4o_slsm_judge_results.json\n",
            "Saved: outputs_first50/gpt4o_slsm_judge_results.csv\n",
            "Done. SLSM judge results saved to outputs_first50/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# Compare judge CSV: Baseline vs SLSM (first 50)\n",
        "# Produces: summary CSV + LaTeX table + win-rate stats\n",
        "# =========================\n",
        "\n",
        "%cd /content/multi-challenge\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "# ---- configure paths ----\n",
        "BASE_CSV = Path(\"outputs_first50/gpt4o_baseline_judge_results.csv\")\n",
        "SLSM_CSV = Path(\"outputs_first50/gpt4o_slsm_judge_results.csv\")\n",
        "\n",
        "assert BASE_CSV.exists(), f\"Missing: {BASE_CSV}\"\n",
        "assert SLSM_CSV.exists(), f\"Missing: {SLSM_CSV}\"\n",
        "\n",
        "base = pd.read_csv(BASE_CSV)\n",
        "slsm = pd.read_csv(SLSM_CSV)\n",
        "\n",
        "print(\"Baseline CSV:\", BASE_CSV, \"| rows:\", len(base), \"| cols:\", len(base.columns))\n",
        "print(\"SLSM CSV    :\", SLSM_CSV, \"| rows:\", len(slsm), \"| cols:\", len(slsm.columns))\n",
        "\n",
        "# ---- find ID column (judge_eval expects QUESTION_ID usually) ----\n",
        "id_candidates = [\"QUESTION_ID\", \"question_id\", \"qid\", \"id\"]\n",
        "id_col = None\n",
        "for c in id_candidates:\n",
        "    if c in base.columns and c in slsm.columns:\n",
        "        id_col = c\n",
        "        break\n",
        "if id_col is None:\n",
        "    # fallback: any common column containing 'id'\n",
        "    commons = set(base.columns) & set(slsm.columns)\n",
        "    for c in commons:\n",
        "        if \"id\" in c.lower():\n",
        "            id_col = c\n",
        "            break\n",
        "assert id_col is not None, f\"Cannot find common ID column. baseline cols={list(base.columns)}\"\n",
        "\n",
        "# ---- merge and suffix ----\n",
        "df = base.merge(slsm, on=id_col, how=\"inner\", suffixes=(\"_base\", \"_slsm\"))\n",
        "assert len(df) > 0, \"Merged dataframe is empty. IDs between baseline and SLSM don't match.\"\n",
        "print(\"ID column:\", id_col, \"| merged rows:\", len(df))\n",
        "\n",
        "# ---- detect metric pairs (numeric columns that exist in both with suffixes) ----\n",
        "num_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
        "num_cols = [c for c in num_cols if c != id_col]\n",
        "\n",
        "pairs = []\n",
        "for c in num_cols:\n",
        "    if c.endswith(\"_base\"):\n",
        "        c2 = c[:-5] + \"_slsm\"\n",
        "        if c2 in df.columns:\n",
        "            pairs.append((c, c2))\n",
        "\n",
        "assert pairs, f\"No paired metrics found. Numeric cols = {num_cols[:30]}\"\n",
        "\n",
        "# ---- bootstrap CI helper ----\n",
        "rng = np.random.default_rng(0)\n",
        "\n",
        "def bootstrap_ci_mean_diff(x, y, n_boot=5000, alpha=0.05):\n",
        "    \"\"\"\n",
        "    Returns (mean_diff, ci_low, ci_high) for (y-x) using bootstrap over paired samples.\n",
        "    \"\"\"\n",
        "    diffs = (y - x).astype(float)\n",
        "    n = diffs.shape[0]\n",
        "    idx = rng.integers(0, n, size=(n_boot, n))\n",
        "    boot_means = diffs[idx].mean(axis=1)\n",
        "    lo = np.quantile(boot_means, alpha/2)\n",
        "    hi = np.quantile(boot_means, 1 - alpha/2)\n",
        "    return float(diffs.mean()), float(lo), float(hi)\n",
        "\n",
        "rows = []\n",
        "for b, s in pairs:\n",
        "    metric = b[:-5]  # remove \"_base\"\n",
        "    x = df[b].to_numpy()\n",
        "    y = df[s].to_numpy()\n",
        "\n",
        "    base_mean = float(np.mean(x))\n",
        "    slsm_mean = float(np.mean(y))\n",
        "    dmean, dlo, dhi = bootstrap_ci_mean_diff(x, y)\n",
        "\n",
        "    win = float(np.mean(y > x))\n",
        "    tie = float(np.mean(y == x))\n",
        "    lose = float(np.mean(y < x))\n",
        "\n",
        "    rows.append({\n",
        "        \"metric\": metric,\n",
        "        \"baseline_mean\": base_mean,\n",
        "        \"slsm_mean\": slsm_mean,\n",
        "        \"delta_mean\": dmean,\n",
        "        \"delta_ci_low\": dlo,\n",
        "        \"delta_ci_high\": dhi,\n",
        "        \"win_rate\": win,\n",
        "        \"tie_rate\": tie,\n",
        "        \"lose_rate\": lose,\n",
        "        \"n\": int(len(x)),\n",
        "    })\n",
        "\n",
        "summary = pd.DataFrame(rows).sort_values(\"metric\").reset_index(drop=True)\n",
        "\n",
        "# ---- pretty print ----\n",
        "pd.set_option(\"display.max_rows\", 200)\n",
        "pd.set_option(\"display.max_columns\", 200)\n",
        "print(\"\\n=== METRIC SUMMARY (means / Δ / CI / win-rate) ===\")\n",
        "display(summary)\n",
        "\n",
        "# ---- build LaTeX (booktabs) ----\n",
        "def fmt(x, nd=3):\n",
        "    return f\"{x:.{nd}f}\"\n",
        "\n",
        "latex = []\n",
        "latex += [r\"\\begin{table}[t]\",\n",
        "          r\"\\centering\",\n",
        "          r\"\\small\",\n",
        "          r\"\\begin{tabular}{lrrrr}\",\n",
        "          r\"\\toprule\",\n",
        "          r\"Metric & Baseline & SLSM & $\\Delta$ (boot 95\\% CI) & Win-rate \\\\\",\n",
        "          r\"\\midrule\"]\n",
        "\n",
        "for _, r in summary.iterrows():\n",
        "    metric = r[\"metric\"]\n",
        "    base_m = fmt(r[\"baseline_mean\"])\n",
        "    slsm_m = fmt(r[\"slsm_mean\"])\n",
        "    d = fmt(r[\"delta_mean\"])\n",
        "    lo = fmt(r[\"delta_ci_low\"])\n",
        "    hi = fmt(r[\"delta_ci_high\"])\n",
        "    win = f\"{100*r['win_rate']:.1f}\" + r\"\\%\"\n",
        "    latex.append(f\"{metric} & {base_m} & {slsm_m} & {d} [{lo}, {hi}] & {win} \\\\\\\\\")\n",
        "\n",
        "latex += [r\"\\bottomrule\",\n",
        "          r\"\\end{tabular}\",\n",
        "          r\"\\caption{Judge scores on the first 50 Multi-Challenge samples: baseline GPT-4o vs SLSM-controlled GPT-4o (controller: GPT-4o-mini). $\\Delta$ denotes SLSM minus baseline with paired bootstrap 95\\% confidence intervals; win-rate is the fraction of samples where SLSM scores strictly higher than baseline.}\",\n",
        "          r\"\\label{tab:mc_first50_judge}\",\n",
        "          r\"\\end{table}\"]\n",
        "\n",
        "latex = \"\\n\".join(latex)\n",
        "\n",
        "print(\"\\n=== LaTeX TABLE (copy/paste) ===\\n\")\n",
        "print(latex)\n",
        "\n",
        "# ---- save artifacts ----\n",
        "out_dir = Path(\"outputs_first50\")\n",
        "out_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "summary_path = out_dir / \"baseline_vs_slsm_summary_first50.csv\"\n",
        "tex_path = out_dir / \"baseline_vs_slsm_table_first50.tex\"\n",
        "\n",
        "summary.to_csv(summary_path, index=False)\n",
        "tex_path.write_text(latex, encoding=\"utf-8\")\n",
        "\n",
        "print(\"\\nSaved summary CSV:\", summary_path)\n",
        "print(\"Saved LaTeX table :\", tex_path)\n",
        "\n",
        "# ---- quick one-line headline (overall, if present) ----\n",
        "def find_overall_metric_name():\n",
        "    candidates = [\"overall_score\", \"OVERALL_SCORE\", \"score\", \"SCORE\"]\n",
        "    for c in candidates:\n",
        "        if c in summary[\"metric\"].values:\n",
        "            return c\n",
        "    return None\n",
        "\n",
        "overall_name = find_overall_metric_name()\n",
        "if overall_name:\n",
        "    r = summary[summary[\"metric\"] == overall_name].iloc[0]\n",
        "    print(f\"\\nHeadline ({overall_name}): baseline={r['baseline_mean']:.3f} | slsm={r['slsm_mean']:.3f} | Δ={r['delta_mean']:.3f} [{r['delta_ci_low']:.3f}, {r['delta_ci_high']:.3f}] | win={100*r['win_rate']:.1f}%\")\n"
      ],
      "metadata": {
        "id": "5d3XrD9Jvslw",
        "outputId": "2715a8df-2761-458b-a55d-fe9f7e2328e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 555
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/multi-challenge\n",
            "Baseline CSV: outputs_first50/gpt4o_baseline_judge_results.csv | rows: 273 | cols: 11\n",
            "SLSM CSV    : outputs_first50/gpt4o_slsm_judge_results.csv | rows: 273 | cols: 11\n",
            "ID column: question_id | merged rows: 273\n",
            "\n",
            "=== METRIC SUMMARY (means / Δ / CI / win-rate) ===\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "           metric  baseline_mean  slsm_mean  delta_mean  delta_ci_low  \\\n",
              "0  attempt_number            1.0        1.0         0.0           0.0   \n",
              "\n",
              "   delta_ci_high  win_rate  tie_rate  lose_rate    n  \n",
              "0            0.0       0.0       1.0        0.0  273  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a0ab4a62-f8bc-4fde-8443-416fbd978230\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>metric</th>\n",
              "      <th>baseline_mean</th>\n",
              "      <th>slsm_mean</th>\n",
              "      <th>delta_mean</th>\n",
              "      <th>delta_ci_low</th>\n",
              "      <th>delta_ci_high</th>\n",
              "      <th>win_rate</th>\n",
              "      <th>tie_rate</th>\n",
              "      <th>lose_rate</th>\n",
              "      <th>n</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>attempt_number</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>273</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a0ab4a62-f8bc-4fde-8443-416fbd978230')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a0ab4a62-f8bc-4fde-8443-416fbd978230 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a0ab4a62-f8bc-4fde-8443-416fbd978230');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "  <div id=\"id_603474a3-fafc-4916-8e4d-c9f0f672612b\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('summary')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_603474a3-fafc-4916-8e4d-c9f0f672612b button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('summary');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "summary",
              "summary": "{\n  \"name\": \"summary\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"metric\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"attempt_number\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"baseline_mean\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 1.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"slsm_mean\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 1.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"delta_mean\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.0,\n        \"max\": 0.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"delta_ci_low\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.0,\n        \"max\": 0.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"delta_ci_high\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.0,\n        \"max\": 0.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"win_rate\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.0,\n        \"max\": 0.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tie_rate\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 1.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lose_rate\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.0,\n        \"max\": 0.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"n\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 273,\n        \"max\": 273,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          273\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== LaTeX TABLE (copy/paste) ===\n",
            "\n",
            "\\begin{table}[t]\n",
            "\\centering\n",
            "\\small\n",
            "\\begin{tabular}{lrrrr}\n",
            "\\toprule\n",
            "Metric & Baseline & SLSM & $\\Delta$ (boot 95\\% CI) & Win-rate \\\\\n",
            "\\midrule\n",
            "attempt_number & 1.000 & 1.000 & 0.000 [0.000, 0.000] & 0.0\\% \\\\\n",
            "\\bottomrule\n",
            "\\end{tabular}\n",
            "\\caption{Judge scores on the first 50 Multi-Challenge samples: baseline GPT-4o vs SLSM-controlled GPT-4o (controller: GPT-4o-mini). $\\Delta$ denotes SLSM minus baseline with paired bootstrap 95\\% confidence intervals; win-rate is the fraction of samples where SLSM scores strictly higher than baseline.}\n",
            "\\label{tab:mc_first50_judge}\n",
            "\\end{table}\n",
            "\n",
            "Saved summary CSV: outputs_first50/baseline_vs_slsm_summary_first50.csv\n",
            "Saved LaTeX table : outputs_first50/baseline_vs_slsm_table_first50.tex\n"
          ]
        }
      ]
    }
  ]
}